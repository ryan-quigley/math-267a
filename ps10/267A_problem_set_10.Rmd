---
output: pdf_document
header-includes:
   - \usepackage{dsfont}
fontsize: 12pt
geometry: margin=0.75in
---
\begin{flushright}
Navid Morshed, Han Xu, Ryan Quigley \\
MATH 267A \\
Section 2  \\
Group A  \\
\end{flushright}
\begin{center}
Problem Set 10
\end{center}

```{r, echo = FALSE}
load("ps10p1.RData")
```
1.
a) 4/100 intervals fail to capture the true mean. This is not surprising because sampling variation can cause the coverage of the confidence interval to differ slightly from 95% exactly. If we draw an infinite number of samples of the same size from the same population and calculate a confidence interval for each sample, the coverage of the intervals would be 95%; in other words, in the limit we expect the coverage of the intervals to approach 95%.  

    ```{r, echo = FALSE, fig.align = "center"}
    alpha <- 0.05
    m <- 100
    n <- 30
    sigma2 <- 25
    
    # CI
    width <- qnorm(p = (1 - alpha/2))*sqrt(sigma2/n)
    x.bar <- rowMeans(normal)
    ci.bounds <- cbind(x.bar - width, x.bar + width)
    
    
    # Plot
    plot(1, 10, axes = FALSE, ann = FALSE, 
    	xlim = c(floor(min(ci.bounds[,1])), ceiling(max(ci.bounds[,2]))),
    	ylim = c(-3,110), 
    	type = "n")
    ci.fail <- 0
    for (i in 1:m) {
    	if (10 < ci.bounds[i, 1] | 10 > ci.bounds[i, 2]) {
    		clr <- "violetred"
    		ci.fail <- ci.fail + 1
    	} else {
    		clr <- "gray75"
    	}
    	lines(ci.bounds[i, ], rep(i+7,2), col = clr)
    }
    lines(rep(10, 2), c(0, 110), col = "gray50", lwd = 1.5, lty = 3)
    axis(1, labels = FALSE, tick = TRUE, lwd = 1.5, lwd.tick = 0, col = "gray50", pos = 0, cex.axis = 0.75)
    axis(1, at = 10, labels = 10, lwd = 0, lwd.tick = 1.5, col = "gray50", pos = 0, cex.axis = 0.75)
    title(main = "95% Confidence Intervals (100 samples)", 
          sub = paste(ci.fail,"/100 fail to capture true mean", sep = ""), 
          line = 2, cex.main = 0.75, cex.sub = 0.75)
    ```

b) 21/100 intervals fail to capture the true mean. Again, sampling variation can cause the coverage of the confidence interval to differ slightly from 80% exactly, but we expect the coverage to approach 80% in the limit. The width of the 80% confidence intervals is narrower (2.34 compared to 3.58) because we must sacrifice confidence in order to gain higher accuracy.  

    ```{r, echo = FALSE, fig.align = "center"}
    alpha <- 0.20
    m <- 100
    n <- 30
    sigma2 <- 25
    
    # CI
    width <- qnorm(p = (1 - alpha/2))*sqrt(sigma2/n)
    x.bar <- rowMeans(normal)
    ci.bounds <- cbind(x.bar - width, x.bar + width)
    
    # Plot
    plot(1, 10, axes = FALSE, ann = FALSE, 
    	xlim = c(floor(min(ci.bounds[,1])), ceiling(max(ci.bounds[,2]))),
    	ylim = c(-3,110), 
    	type = "n")
    ci.fail <- 0
    for (i in 1:m) {
    	if (10 < ci.bounds[i, 1] | 10 > ci.bounds[i, 2]) {
    		clr <- "violetred"
    		ci.fail <- ci.fail + 1
    	} else {
    		clr <- "gray75"
    	}
    	lines(ci.bounds[i, ], rep(i+7,2), col = clr)
    }
    lines(rep(10, 2), c(0, 110), col = "gray50", lwd = 1.5, lty = 3)
    axis(1, labels = FALSE, tick = TRUE, lwd = 1.5, lwd.tick = 0, col = "gray50", pos = 0, cex.axis = 0.75)
    axis(1, at = 10, labels = 10, lwd = 0, lwd.tick = 1.5, col = "gray50", pos = 0, cex.axis = 0.75)
    title(main = "80% Confidence Intervals (100 samples)", 
          sub = paste(ci.fail,"/100 fail to capture true mean", sep = ""), 
          line = 2, cex.main = 0.75, cex.sub = 0.75)
    ```

c) It is worth noting that one of the conditions for normal approximation is not met: $p\cdot n = 0.05 \cdot 30 = 1.5 \ngeq 10$. 25% of Wald intervals fail to capture the true proportion, 5% of score intervals fail to capture the true proportion. There does not appear to be any benefit to using asymptotic interval estimators for binomial proportions. They produce intervals with bounds outside the parameter space, and they fail to calculate an interval when the number of successes in the sample is 0.  

    ```{r, echo = FALSE}
    p <- 0.05
    
    num.success <- rowSums(bernoulli)
    ci.wald <- binom::binom.confint(num.success, n, conf.level = 0.95, methods = "asymptotic")
    ci.wilson <- binom::binom.confint(num.success, n, conf.level = 0.95, methods = "wilson")
    
    margins <- par("mar")
    par(mfrow = c(1,2), mar = margins + c(0,-3,0,-1))
    
    # Plot: wald
    plot(0.05, 10, axes = FALSE, ann = FALSE, 
    	xlim = c(-0.05, 0.3),
    	ylim = c(-3,110), 
    	type = "n")
    lines(rep(0.05, 2), c(0, 110), col = "gray50", lwd = 1.5, lty = 3)
    lines(rep(0, 2), c(0, 110), col = "gray50", lwd = 1.5, lty = 3)
    ci.fail <- 0
    ci.zero <- 0
    for (i in 1:m) {
    	if (ci.wald$x[i] == 0){
    		points(0, i+7, col = "violetred", pch = 20, cex = 0.50)
    		ci.zero <- ci.zero + 1
    	} else if (0.05 < ci.wald[i, 5] | 0.05 > ci.wald[i, 6]) {
    		clr <- "violetred"
    		ci.fail <- ci.fail + 1
    		lines(ci.wald[i, c(5, 6)], rep(i+7,2), col = clr)
    	} else {
    		clr <- "gray75"
    		lines(ci.wald[i, c(5, 6)], rep(i+7,2), col = clr)
    	}
    }
    axis(1, labels = FALSE, tick = TRUE, lwd = 1.5, lwd.tick = 0, col = "gray50", pos = 0, cex.axis = 0.75)
    axis(1, at = c(0, 0.05), labels = c(0, 0.05), lwd = 0, lwd.tick = 1.5, col = "gray50", pos = 0, cex.axis = 0.75)
    title(main = "95% Wald Intervals (100 samples)", 
          sub = paste(ci.fail + ci.zero,"% fail to capture true proportion", sep = ""), 
          line = 2, cex.main = 0.75, cex.sub = 0.75)
    
    
    # Plot: wilson
    plot(0.05, 10, axes = FALSE, ann = FALSE, 
    	xlim = c(-0.05, 0.3),
    	ylim = c(-3,110), 
    	type = "n")
    lines(rep(0.05, 2), c(0, 110), col = "gray50", lwd = 1.5, lty = 3)
    lines(rep(0, 2), c(0, 110), col = "gray50", lwd = 1.5, lty = 3)
    ci.fail <- 0
    for (i in 1:m) {
    	if (0.05 < ci.wilson[i, 5] | 0.05 > ci.wilson[i, 6]) {
    		clr <- "violetred"
    		ci.fail <- ci.fail + 1
    	} else {
    		clr <- "gray75"
    	}
    	lines(ci.wilson[i, c(5, 6)], rep(i+7,2), col = clr)
    }
    axis(1, labels = FALSE, tick = TRUE, lwd = 1.5, lwd.tick = 0, col = "gray50", pos = 0, cex.axis = 0.75)
    axis(1, at = c(0, 0.05), labels = c(0, 0.05), lwd = 0, lwd.tick = 1.5, col = "gray50", pos = 0, cex.axis = 0.75)
    title(main = "95% Score Intervals (100 samples)", 
          sub = paste(ci.fail,"% fail to capture true proportion", sep = ""), 
          line = 2, cex.main = 0.75, cex.sub = 0.75)
    ```

2.
a) No discussion required  
b) The 98% confidence interval for the average time between events, $1/\lambda$, is (6.33, 28.78)  
c) In order to guarantee that the confidence interval contains the true value for the average time between events, the interval must be the entire support of the distribution: the support of the $\chi^2$ distribution is $[0, \infty)$  

    ```{r, echo = FALSE}
    ciExp <- function(x, alpha) {
    	if (!is.numeric(x)) {
    		stop("x must be a numeric vector")
    	}
    	if (alpha < 0 | alpha > 1) {
    		stop("alpha must be in the interval (0, 1)")
    	}
    	if (any(is.na(x))) {
    		warning(paste(sum(is.na(x)), "NAs removed from x, sample size reduced."))
    	}
    	n <- length(x[!is.na(x)])
    	lambda.hat <- 1/mean(x, na.rm = TRUE)
    	chi.sq.q <- qchisq(p = c(1 - alpha/2, alpha/2), df = 2*n)
    	ci <- round((2*n)/(lambda.hat*chi.sq.q), 2)
    	names(ci) <- c("lcl", "ucl")
    	ci
    }
    arv.time <- c(28.62, 2.14, 8.14, 2.17, 5.72, 10.64, 6.89, 32.09, 19.37, 3.07)
    ```
    
    ```{r}
    ciExp(arv.time, alpha = 0)
    ```
    
3.
a) The null hypothesis: the previous survey results are still accurate and relevant. The alternative hypothesis: the old survey results are outdated and logging cars are actually being loaded more heavily in recent years.  

    \begin{align*}
    H_0: & \mu \leq 140 \\
    H_a: & \mu > 140
    \end{align*}
    
    We want to determine whether or not to build the trestle to higher tolerances to accommodate heavier cars, so we are really only interested in the case where the average weight is greater than the hypothesized value. Thus, a one-sided test is appropriate.  
    
    In this context, type II error is a very serious problem. If we fail to reject the null hypothesis when in reality the average weight is greater than 140, then the engineering corps will not build the trestle to higher tolerances and the trestle will be at greater risk of structural failure. We can control type II error by making the rejection region larger, which can be achieved by choosing a smaller critical value. Determining that particular value should be left to the engineers, but for the sake of proceeding with the test we will choose a single number from the set of values associated with the alternative hypothesis. Say at a true average weight of 150 we want to make sure the type II error is at most 1%. We can calculate the critical value by solving the following equation for $c$:  
    
    \begin{align*}
    t_{\beta, n - 1} & = \frac{c - \mu_a}{s/\sqrt{n}} \\
    t_{0.01, 19} & = \frac{c - 150}{14.44/\sqrt{20}} \\
    \implies c & = 150 - 2.54\cdot \frac{14.44}{\sqrt{20}} \\
    & = 141.83
    \end{align*}
    
    Thus, our rejection region is $\bar{X} \geq 141.83$. In terms of quantiles, this correpondes to $t > \frac{141.83 - 140}{14.44/\sqrt{20}} = 0.57$  
b) In order to justify performing a t-test, we must assume the underlying population is normally distributed. Assuming that is the case, the t-test is appropriate because we do not know the population standard deviation and our sample size is not large enough to justify a large-sample asymptotic test. The `t.test()` gives a $t$ value of 1.97, which is significantly larger than our critical value, 0.57. Thus, we reject the null hypothesis and conclude that the average weight of loaded logging cars is greater than 140.  

    ```{r, echo = FALSE}
    load("ps10p3.RData")
    t.test(x = trains, mu = 140, alternative = "greater")
    ```
c) The t-test from part (b) only allows us to advise the engineers to build the trestle to higher tolerance; however, it does not allow us to suggest a minimum threshold for the tolerance. We would need to construct a confidence interval in order to provide the engineers with suggested tolerance minimums.  
d) In light of the new information, the results of the initial t-test are invalid. The data is not a random sample from the population of logging cars, so it is not an appropriate sample to use to test the average weight of logging cars, $\mu$.